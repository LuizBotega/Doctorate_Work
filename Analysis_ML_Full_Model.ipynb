{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import fbeta_score, accuracy_score, r2_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "import visuals as vs\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataframe raw.csv', sep = ';')\n",
    "df_final = pd.read_csv('DataFrame.csv', sep = ';', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separation of input, middle and output for the full model\n",
    "\n",
    "df_input = df_final.iloc[:,1:16].drop(['ES Service'], axis= 1)\n",
    "df_middle = df_final.iloc[:,16:]\n",
    "\n",
    "added_to_second = ['DS Discover', 'DS Define','DS Develop', 'DS Deliver', 'ES Product', 'Team size min',\n",
    "                   'Part Users', 'Part Experts', 'Part Service staff', 'Part Stakeholders']\n",
    "df_middle_second = pd.concat([df_middle, df_final[added_to_second]], axis = 1)\n",
    "\n",
    "mapping_names = {name['Name']: index for index, name in df.iterrows()}\n",
    "df_output = df_final['Name'].map(mapping_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100 / 100"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9838518518518515"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "correct_sum = 0\n",
    "iterations = 100\n",
    "i = 0\n",
    "\n",
    "while i < iterations:\n",
    "    try:\n",
    "        #first part\n",
    "        estimators = {}\n",
    "\n",
    "        for column in df_middle:\n",
    "            X_train_first, X_test_first, y_train_first, y_test_first = train_test_split(df_input, df_middle[column],\n",
    "                                                                                    test_size = 0.25, random_state = int(time.time()))\n",
    "\n",
    "            estimator = GradientBoostingRegressor(learning_rate = 0.4, n_estimators = 25, max_depth = 5)\n",
    "            estimators.update({column: estimator.fit(X_train_first,y_train_first)})\n",
    "\n",
    "        predicted_values_first = pd.DataFrame(index = X_test_first.index.values, columns = df_middle.columns.values)\n",
    "\n",
    "        for _, row in X_test_first.iterrows():\n",
    "            for feature in df_middle.columns.values:\n",
    "                new_case = pd.DataFrame([np.array(row)], columns = df_input.columns.values)\n",
    "                predicted_values_first[feature].loc[row.name] = estimators[feature].predict(new_case)\n",
    "\n",
    "        #second part\n",
    "        X_train_second = df_middle_second.iloc[X_train_first.index.values]\n",
    "        y_train_second = df_output.iloc[y_train_first.index.values]\n",
    "        X_test_second = pd.concat([predicted_values_first, X_test_first[added_to_second]], axis = 1)\n",
    "        y_test_second = df_output.iloc[y_test_first.index.values]\n",
    "\n",
    "        model = LogisticRegression(multi_class = 'multinomial', solver = 'newton-cg', C = 0.7)\n",
    "\n",
    "        model.fit(X_train_second, y_train_second)\n",
    "\n",
    "        predicted_values_second = pd.DataFrame(index = X_test_second.index.values, columns = df['Name'])\n",
    "\n",
    "        for _, row in X_test_second.iterrows():\n",
    "            new_case = pd.DataFrame([np.array(row)], columns = X_test_second.columns.values)\n",
    "            predicted_values_second.loc[row.name] = model.predict_proba(new_case)\n",
    "\n",
    "        '''for j, row in X_test_first.iterrows():\n",
    "            design_step = row[:4].idxmax(axis=1)\n",
    "            predicted_values_second.loc[j,:][df['Name'][df.loc[:,design_step]!=0].unique()] *= 1.25'''\n",
    "\n",
    "        results = pd.DataFrame(index = X_test_second.index.values, columns = ['first', 'proba', 'second', 'proba',\n",
    "                                                                              'third', 'proba'])\n",
    "        for _, row in predicted_values_second.iterrows():\n",
    "            best_three = np.array(sorted(zip(row, df['Name']), reverse=True)[:3])[:,1]\n",
    "            results.loc[row.name] = [best_three[0], predicted_values_second.loc[row.name, best_three[0]],\n",
    "                                     best_three[1], predicted_values_second.loc[row.name, best_three[1]],\n",
    "                                     best_three[2], predicted_values_second.loc[row.name, best_three[2]]]\n",
    "\n",
    "        remapping_names = {index: name['Name'] for index, name in df.iterrows()}\n",
    "        y_check = y_test_second.map(remapping_names)\n",
    "\n",
    "        results['check'] = np.nan\n",
    "\n",
    "        for index in y_check.index.values:\n",
    "            results.loc[index, 'check'] = y_check.loc[index] in np.array(results.loc[index])\n",
    "\n",
    "        results['true'] = y_check\n",
    "        correct_sum += results['check'].sum()/results.shape[0]\n",
    "        i += 1\n",
    "    except:\n",
    "        None\n",
    "    print('\\r {} / {}'.format(i, iterations), end='')\n",
    "        \n",
    "correct_sum/iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>proba</th>\n",
       "      <th>second</th>\n",
       "      <th>proba</th>\n",
       "      <th>third</th>\n",
       "      <th>proba</th>\n",
       "      <th>check</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Mind Map</td>\n",
       "      <td>0.54719</td>\n",
       "      <td>5 Whys</td>\n",
       "      <td>0.0954769</td>\n",
       "      <td>Contextual Interview</td>\n",
       "      <td>0.0586036</td>\n",
       "      <td>True</td>\n",
       "      <td>Mind Map</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Functional Analysis</td>\n",
       "      <td>0.575557</td>\n",
       "      <td>Mind Map</td>\n",
       "      <td>0.107529</td>\n",
       "      <td>Brainwriting</td>\n",
       "      <td>0.0827025</td>\n",
       "      <td>True</td>\n",
       "      <td>Functional Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Storyboard</td>\n",
       "      <td>0.791626</td>\n",
       "      <td>How Might We</td>\n",
       "      <td>0.0280784</td>\n",
       "      <td>Blueprint</td>\n",
       "      <td>0.0271086</td>\n",
       "      <td>True</td>\n",
       "      <td>Storyboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>Alpha Prototyping</td>\n",
       "      <td>0.840303</td>\n",
       "      <td>Storyboard</td>\n",
       "      <td>0.0472827</td>\n",
       "      <td>Rough Prototyping</td>\n",
       "      <td>0.0410314</td>\n",
       "      <td>True</td>\n",
       "      <td>Alpha Prototyping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Affinity Diagram</td>\n",
       "      <td>0.511415</td>\n",
       "      <td>Dot Voting</td>\n",
       "      <td>0.143054</td>\n",
       "      <td>How Might We</td>\n",
       "      <td>0.0621829</td>\n",
       "      <td>True</td>\n",
       "      <td>Affinity Diagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Mind Map</td>\n",
       "      <td>0.585985</td>\n",
       "      <td>5 Whys</td>\n",
       "      <td>0.0828303</td>\n",
       "      <td>Impact Matrix</td>\n",
       "      <td>0.0737962</td>\n",
       "      <td>True</td>\n",
       "      <td>Mind Map</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>Functional Analysis</td>\n",
       "      <td>0.807802</td>\n",
       "      <td>How Might We</td>\n",
       "      <td>0.0470245</td>\n",
       "      <td>Traditional Brainstorming</td>\n",
       "      <td>0.0273487</td>\n",
       "      <td>True</td>\n",
       "      <td>Functional Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Mind Map</td>\n",
       "      <td>0.369347</td>\n",
       "      <td>Reverse Brainstorming</td>\n",
       "      <td>0.126656</td>\n",
       "      <td>Rough Prototyping</td>\n",
       "      <td>0.110576</td>\n",
       "      <td>True</td>\n",
       "      <td>Rough Prototyping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>Alpha Prototyping</td>\n",
       "      <td>0.848729</td>\n",
       "      <td>Rough Prototyping</td>\n",
       "      <td>0.0427808</td>\n",
       "      <td>Storyboard</td>\n",
       "      <td>0.0399857</td>\n",
       "      <td>True</td>\n",
       "      <td>Alpha Prototyping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Mind Map</td>\n",
       "      <td>0.594098</td>\n",
       "      <td>5 Whys</td>\n",
       "      <td>0.082346</td>\n",
       "      <td>Impact Matrix</td>\n",
       "      <td>0.0693876</td>\n",
       "      <td>True</td>\n",
       "      <td>Mind Map</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>Impact Matrix</td>\n",
       "      <td>0.680208</td>\n",
       "      <td>Mind Map</td>\n",
       "      <td>0.0933124</td>\n",
       "      <td>Dot Voting</td>\n",
       "      <td>0.0483708</td>\n",
       "      <td>True</td>\n",
       "      <td>Impact Matrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Impact Matrix</td>\n",
       "      <td>0.676485</td>\n",
       "      <td>Mind Map</td>\n",
       "      <td>0.0858365</td>\n",
       "      <td>Dot Voting</td>\n",
       "      <td>0.044679</td>\n",
       "      <td>True</td>\n",
       "      <td>Impact Matrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>Persona</td>\n",
       "      <td>0.635416</td>\n",
       "      <td>Contextual Interview</td>\n",
       "      <td>0.0609517</td>\n",
       "      <td>Shadowing</td>\n",
       "      <td>0.0496207</td>\n",
       "      <td>True</td>\n",
       "      <td>Persona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>Mind Map</td>\n",
       "      <td>0.401584</td>\n",
       "      <td>Rough Prototyping</td>\n",
       "      <td>0.132629</td>\n",
       "      <td>Reverse Brainstorming</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>True</td>\n",
       "      <td>Rough Prototyping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Rough Prototyping</td>\n",
       "      <td>0.199674</td>\n",
       "      <td>Storyboard</td>\n",
       "      <td>0.0931698</td>\n",
       "      <td>Alpha Prototyping</td>\n",
       "      <td>0.09122</td>\n",
       "      <td>True</td>\n",
       "      <td>Rough Prototyping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>Functional Analysis</td>\n",
       "      <td>0.28505</td>\n",
       "      <td>Brainwriting</td>\n",
       "      <td>0.240649</td>\n",
       "      <td>Mind Map</td>\n",
       "      <td>0.186584</td>\n",
       "      <td>True</td>\n",
       "      <td>Functional Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>Alpha Prototyping</td>\n",
       "      <td>0.760768</td>\n",
       "      <td>Rough Prototyping</td>\n",
       "      <td>0.0854983</td>\n",
       "      <td>Storyboard</td>\n",
       "      <td>0.0564587</td>\n",
       "      <td>True</td>\n",
       "      <td>Alpha Prototyping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Brainwriting</td>\n",
       "      <td>0.438799</td>\n",
       "      <td>Traditional Brainstorming</td>\n",
       "      <td>0.14615</td>\n",
       "      <td>Reverse Brainstorming</td>\n",
       "      <td>0.126525</td>\n",
       "      <td>True</td>\n",
       "      <td>Brainwriting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>5 Whys</td>\n",
       "      <td>0.474409</td>\n",
       "      <td>Mind Map</td>\n",
       "      <td>0.169027</td>\n",
       "      <td>How Might We</td>\n",
       "      <td>0.0933378</td>\n",
       "      <td>True</td>\n",
       "      <td>5 Whys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Impact Matrix</td>\n",
       "      <td>0.649167</td>\n",
       "      <td>Stakeholder Map</td>\n",
       "      <td>0.0924234</td>\n",
       "      <td>Rough Prototyping</td>\n",
       "      <td>0.0394582</td>\n",
       "      <td>True</td>\n",
       "      <td>Impact Matrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>Blueprint</td>\n",
       "      <td>0.573094</td>\n",
       "      <td>Contextual Interview</td>\n",
       "      <td>0.260036</td>\n",
       "      <td>Storyboard</td>\n",
       "      <td>0.0437603</td>\n",
       "      <td>True</td>\n",
       "      <td>Contextual Interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>Blueprint</td>\n",
       "      <td>0.90029</td>\n",
       "      <td>Contextual Interview</td>\n",
       "      <td>0.0308214</td>\n",
       "      <td>Storyboard</td>\n",
       "      <td>0.0214722</td>\n",
       "      <td>True</td>\n",
       "      <td>Blueprint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>How Might We</td>\n",
       "      <td>0.765027</td>\n",
       "      <td>Affinity Diagram</td>\n",
       "      <td>0.068024</td>\n",
       "      <td>5 Whys</td>\n",
       "      <td>0.0563033</td>\n",
       "      <td>True</td>\n",
       "      <td>How Might We</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>Impact Matrix</td>\n",
       "      <td>0.689322</td>\n",
       "      <td>Mind Map</td>\n",
       "      <td>0.0923592</td>\n",
       "      <td>Dot Voting</td>\n",
       "      <td>0.0453426</td>\n",
       "      <td>True</td>\n",
       "      <td>Impact Matrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>How Might We</td>\n",
       "      <td>0.759599</td>\n",
       "      <td>Affinity Diagram</td>\n",
       "      <td>0.069617</td>\n",
       "      <td>5 Whys</td>\n",
       "      <td>0.057146</td>\n",
       "      <td>True</td>\n",
       "      <td>How Might We</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Storyboard</td>\n",
       "      <td>0.790135</td>\n",
       "      <td>How Might We</td>\n",
       "      <td>0.0282772</td>\n",
       "      <td>Blueprint</td>\n",
       "      <td>0.0274447</td>\n",
       "      <td>True</td>\n",
       "      <td>Storyboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Stakeholder Map</td>\n",
       "      <td>0.755632</td>\n",
       "      <td>Impact Matrix</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>Shadowing</td>\n",
       "      <td>0.0360194</td>\n",
       "      <td>True</td>\n",
       "      <td>Stakeholder Map</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Blueprint</td>\n",
       "      <td>0.856149</td>\n",
       "      <td>Contextual Interview</td>\n",
       "      <td>0.0727211</td>\n",
       "      <td>Storyboard</td>\n",
       "      <td>0.0312812</td>\n",
       "      <td>True</td>\n",
       "      <td>Blueprint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>Mind Map</td>\n",
       "      <td>0.636609</td>\n",
       "      <td>5 Whys</td>\n",
       "      <td>0.0761241</td>\n",
       "      <td>Impact Matrix</td>\n",
       "      <td>0.0574362</td>\n",
       "      <td>True</td>\n",
       "      <td>Mind Map</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Functional Analysis</td>\n",
       "      <td>0.69659</td>\n",
       "      <td>Mind Map</td>\n",
       "      <td>0.0612139</td>\n",
       "      <td>How Might We</td>\n",
       "      <td>0.0581277</td>\n",
       "      <td>True</td>\n",
       "      <td>Functional Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>Dot Voting</td>\n",
       "      <td>0.629302</td>\n",
       "      <td>Affinity Diagram</td>\n",
       "      <td>0.132743</td>\n",
       "      <td>Traditional Brainstorming</td>\n",
       "      <td>0.0716821</td>\n",
       "      <td>True</td>\n",
       "      <td>Dot Voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>5 Whys</td>\n",
       "      <td>0.636059</td>\n",
       "      <td>Mind Map</td>\n",
       "      <td>0.0791242</td>\n",
       "      <td>Shadowing</td>\n",
       "      <td>0.0551576</td>\n",
       "      <td>True</td>\n",
       "      <td>5 Whys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Dot Voting</td>\n",
       "      <td>0.715994</td>\n",
       "      <td>Affinity Diagram</td>\n",
       "      <td>0.0886115</td>\n",
       "      <td>Traditional Brainstorming</td>\n",
       "      <td>0.0496728</td>\n",
       "      <td>True</td>\n",
       "      <td>Dot Voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Contextual Interview</td>\n",
       "      <td>0.574458</td>\n",
       "      <td>Mind Map</td>\n",
       "      <td>0.0933308</td>\n",
       "      <td>5 Whys</td>\n",
       "      <td>0.0620524</td>\n",
       "      <td>True</td>\n",
       "      <td>Contextual Interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Mind Map</td>\n",
       "      <td>0.598726</td>\n",
       "      <td>5 Whys</td>\n",
       "      <td>0.092318</td>\n",
       "      <td>Impact Matrix</td>\n",
       "      <td>0.0641278</td>\n",
       "      <td>True</td>\n",
       "      <td>Mind Map</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    first     proba                     second      proba  \\\n",
       "161              Mind Map   0.54719                     5 Whys  0.0954769   \n",
       "114   Functional Analysis  0.575557                   Mind Map   0.107529   \n",
       "48             Storyboard  0.791626               How Might We  0.0280784   \n",
       "524     Alpha Prototyping  0.840303                 Storyboard  0.0472827   \n",
       "107      Affinity Diagram  0.511415                 Dot Voting   0.143054   \n",
       "82               Mind Map  0.585985                     5 Whys  0.0828303   \n",
       "475   Functional Analysis  0.807802               How Might We  0.0470245   \n",
       "149              Mind Map  0.369347      Reverse Brainstorming   0.126656   \n",
       "503     Alpha Prototyping  0.848729          Rough Prototyping  0.0427808   \n",
       "46               Mind Map  0.594098                     5 Whys   0.082346   \n",
       "380         Impact Matrix  0.680208                   Mind Map  0.0933124   \n",
       "139         Impact Matrix  0.676485                   Mind Map  0.0858365   \n",
       "382               Persona  0.635416       Contextual Interview  0.0609517   \n",
       "384              Mind Map  0.401584          Rough Prototyping   0.132629   \n",
       "156     Rough Prototyping  0.199674                 Storyboard  0.0931698   \n",
       "535   Functional Analysis   0.28505               Brainwriting   0.240649   \n",
       "491     Alpha Prototyping  0.760768          Rough Prototyping  0.0854983   \n",
       "143          Brainwriting  0.438799  Traditional Brainstorming    0.14615   \n",
       "100                5 Whys  0.474409                   Mind Map   0.169027   \n",
       "154         Impact Matrix  0.649167            Stakeholder Map  0.0924234   \n",
       "531             Blueprint  0.573094       Contextual Interview   0.260036   \n",
       "455             Blueprint   0.90029       Contextual Interview  0.0308214   \n",
       "350          How Might We  0.765027           Affinity Diagram   0.068024   \n",
       "398         Impact Matrix  0.689322                   Mind Map  0.0923592   \n",
       "334          How Might We  0.759599           Affinity Diagram   0.069617   \n",
       "84             Storyboard  0.790135               How Might We  0.0282772   \n",
       "157       Stakeholder Map  0.755632              Impact Matrix   0.103448   \n",
       "498             Blueprint  0.856149       Contextual Interview  0.0727211   \n",
       "381              Mind Map  0.636609                     5 Whys  0.0761241   \n",
       "129   Functional Analysis   0.69659                   Mind Map  0.0612139   \n",
       "310            Dot Voting  0.629302           Affinity Diagram   0.132743   \n",
       "185                5 Whys  0.636059                   Mind Map  0.0791242   \n",
       "43             Dot Voting  0.715994           Affinity Diagram  0.0886115   \n",
       "291  Contextual Interview  0.574458                   Mind Map  0.0933308   \n",
       "365              Mind Map  0.598726                     5 Whys   0.092318   \n",
       "\n",
       "                         third      proba check                  true  \n",
       "161       Contextual Interview  0.0586036  True              Mind Map  \n",
       "114               Brainwriting  0.0827025  True   Functional Analysis  \n",
       "48                   Blueprint  0.0271086  True            Storyboard  \n",
       "524          Rough Prototyping  0.0410314  True     Alpha Prototyping  \n",
       "107               How Might We  0.0621829  True      Affinity Diagram  \n",
       "82               Impact Matrix  0.0737962  True              Mind Map  \n",
       "475  Traditional Brainstorming  0.0273487  True   Functional Analysis  \n",
       "149          Rough Prototyping   0.110576  True     Rough Prototyping  \n",
       "503                 Storyboard  0.0399857  True     Alpha Prototyping  \n",
       "46               Impact Matrix  0.0693876  True              Mind Map  \n",
       "380                 Dot Voting  0.0483708  True         Impact Matrix  \n",
       "139                 Dot Voting   0.044679  True         Impact Matrix  \n",
       "382                  Shadowing  0.0496207  True               Persona  \n",
       "384      Reverse Brainstorming   0.114691  True     Rough Prototyping  \n",
       "156          Alpha Prototyping    0.09122  True     Rough Prototyping  \n",
       "535                   Mind Map   0.186584  True   Functional Analysis  \n",
       "491                 Storyboard  0.0564587  True     Alpha Prototyping  \n",
       "143      Reverse Brainstorming   0.126525  True          Brainwriting  \n",
       "100               How Might We  0.0933378  True                5 Whys  \n",
       "154          Rough Prototyping  0.0394582  True         Impact Matrix  \n",
       "531                 Storyboard  0.0437603  True  Contextual Interview  \n",
       "455                 Storyboard  0.0214722  True             Blueprint  \n",
       "350                     5 Whys  0.0563033  True          How Might We  \n",
       "398                 Dot Voting  0.0453426  True         Impact Matrix  \n",
       "334                     5 Whys   0.057146  True          How Might We  \n",
       "84                   Blueprint  0.0274447  True            Storyboard  \n",
       "157                  Shadowing  0.0360194  True       Stakeholder Map  \n",
       "498                 Storyboard  0.0312812  True             Blueprint  \n",
       "381              Impact Matrix  0.0574362  True              Mind Map  \n",
       "129               How Might We  0.0581277  True   Functional Analysis  \n",
       "310  Traditional Brainstorming  0.0716821  True            Dot Voting  \n",
       "185                  Shadowing  0.0551576  True                5 Whys  \n",
       "43   Traditional Brainstorming  0.0496728  True            Dot Voting  \n",
       "291                     5 Whys  0.0620524  True  Contextual Interview  \n",
       "365              Impact Matrix  0.0641278  True              Mind Map  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.iloc[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check rows that contain probas below tolerance of 0.01\n",
    "results[results.iloc[:,5] < 0.01].count()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7953652684438636"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check Proba Sum Mean\n",
    "total = []\n",
    "total.append([row.sum() for _, row in results['proba'].iterrows()])\n",
    "np.mean(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17562962962962964"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.random import choice\n",
    "\n",
    "correct_sum = 0\n",
    "iterations = 100\n",
    "weight = np.array(df_final.groupby(['Name'])['Name'].count()/df_final['Name'].count())\n",
    "\n",
    "for i in range(iterations):\n",
    "\n",
    "    random_results = pd.DataFrame(index = y_test_second.index.values, columns = ['first', 'second', 'third'])\n",
    "    for i, row in random_results.iterrows():\n",
    "        random_results.loc[i] = draw = choice(df['Name'], 3, p = weight)\n",
    "\n",
    "    random_results['check'] = np.nan\n",
    "\n",
    "    for index in y_check.index.values:\n",
    "        random_results.loc[index, 'check'] = y_check.loc[index] in np.array(random_results.loc[index])\n",
    "\n",
    "    random_results['true'] = y_check\n",
    "    correct_sum += random_results['check'].sum()/random_results.shape[0]\n",
    "    \n",
    "correct_sum/iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decision tree\n",
    "100% correct, but without finding other 2 adequate CITs. This model would be perfect if I wanted only THE best CIT, but I want the 3 best ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9220351664796115"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "\n",
    "correct_sum = 0\n",
    "iterations = 100\n",
    "\n",
    "for i in range(iterations):\n",
    "    try:\n",
    "    #first part\n",
    "        estimators = {}\n",
    "\n",
    "        for column in df_middle:\n",
    "            X_train_first, X_test_first, y_train_first, y_test_first = train_test_split(df_input, df_middle[column],\n",
    "                                                                                    test_size = 0.25, random_state = int(time.time()))\n",
    "\n",
    "            estimator = DecisionTreeRegressor()\n",
    "            estimators.update({column: estimator.fit(X_train_first,y_train_first)})\n",
    "\n",
    "        predicted_values_first = pd.DataFrame(index = X_test_first.index.values, columns = df_middle.columns.values)\n",
    "\n",
    "        for _, row in X_test_first.iterrows():\n",
    "            for feature in df_middle.columns.values:\n",
    "                new_case = pd.DataFrame([np.array(row)], columns = df_input.columns.values)\n",
    "                predicted_values_first[feature].loc[row.name] = estimators[feature].predict(new_case)\n",
    "\n",
    "        #second part\n",
    "        X_train_second = df_middle_second.iloc[X_train_first.index.values]\n",
    "        y_train_second = df_output.iloc[y_train_first.index.values]\n",
    "        X_test_second = pd.concat([predicted_values_first, X_test_first[added_to_second]], axis = 1)\n",
    "        y_test_second = df_output.iloc[y_test_first.index.values]\n",
    "\n",
    "        model = DecisionTreeClassifier()\n",
    "\n",
    "        model.fit(X_train_second, y_train_second)\n",
    "\n",
    "        predicted_values_second = pd.DataFrame(index = X_test_second.index.values, columns = df['Name'])\n",
    "\n",
    "        for _, row in X_test_second.iterrows():\n",
    "            new_case = pd.DataFrame([np.array(row)], columns = X_test_second.columns.values)\n",
    "            predicted_values_second.loc[row.name] = model.predict_proba(new_case)\n",
    "\n",
    "        results_DT = pd.DataFrame(index = X_test_second.index.values, columns = ['first', 'proba', 'second', 'proba',\n",
    "                                                                                             'third', 'proba'])\n",
    "        for _, row in predicted_values_second.iterrows():\n",
    "            best_three = np.array(sorted(zip(row, df['Name']), reverse=True)[:3])[:,1]\n",
    "            results_DT.loc[row.name] = [best_three[0], predicted_values_second.loc[row.name, best_three[0]],\n",
    "                                     best_three[1], predicted_values_second.loc[row.name, best_three[1]],\n",
    "                                     best_three[2], predicted_values_second.loc[row.name, best_three[2]]]\n",
    "\n",
    "        remapping_names = {index: name['Name'] for index, name in df.iterrows()}\n",
    "        y_check = y_test_second.map(remapping_names)\n",
    "\n",
    "\n",
    "        results_DT['check'] = np.nan\n",
    "\n",
    "        for index in y_check.index.values:\n",
    "            results_DT.loc[index, 'check'] = y_check.loc[index] in np.array(results_DT.loc[index])\n",
    "\n",
    "        results_DT['true'] = y_check\n",
    "        correct_sum += results_DT['check'].sum()/results_DT.shape[0]\n",
    "    except:\n",
    "        iterations -= 1\n",
    "        \n",
    "correct_sum/iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
